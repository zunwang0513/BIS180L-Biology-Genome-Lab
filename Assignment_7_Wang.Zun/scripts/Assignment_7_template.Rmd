---
title: "Assignment 7"
output: 
  html_document: 
    keep_md: yes
    df_print: paged
---

__Student Name:__ Zun Wang
__Student ID:__ 915109847

## Assignment 7: Gene Networks
```{r}
library(tidyverse)
library(ggdendro)
```
```{r}
cities <- read.delim("../input/us_cities.txt",row.names = 1)

head(cities)
```
```{r}
cities_hclust <- cities %>% as.dist() %>% hclust()
ggdendrogram(cities_hclust)
```
```{r}
cities_hclust$height
```


This should be a .Rmd notebook file.  Include this file and the .nb.html when you turn in the assignment.

**EXERCISE 1:** Extending the example that I gave for BOS/NY/DC, what are the distances that define each split in the West Coast side of the hclust plot? 
 
*Hint 1: Start with the distances between SF and LA. Then look at the difference between that cluster up to SEA*  

*Hint 2: Print cities, you only need to look at the upper right triangle of data matrix.*

BOS/NY; 206
NY/DC: 233
BOS/DC: 429

**SDR** -2 Wrong distances/groups


```{r}
# make sure to change the path to where you downloaded this using wget
DE_genes <- read_csv("../input/DEgenes_GxE.csv")
dim(DE_genes)
head(DE_genes) #check out the data
```
```{r}
brass_voom_E <- read_csv("../input/voom_transform_brassica.csv")
head(brass_voom_E[,1:6])
```

```{r}
GxE_counts <- DE_genes %>% select(GeneID) %>% left_join(brass_voom_E) #get count data specifically for the G,xE genes
dim(GxE_counts)
```
```{r}
head(GxE_counts[,1:6])
```
```{r}
GxE_counts <- GxE_counts %>% column_to_rownames("GeneID") %>% as.matrix() # some of the downstream steps require a data matrix
head(GxE_counts[,1:6])
```
```{r}
gene_hclust_row <- GxE_counts %>% dist() %>% hclust()
ggdendrogram(gene_hclust_row)
```
```{r}
gene_hclust_col <- GxE_counts %>% t() %>% dist() %>% hclust()
ggdendrogram(gene_hclust_col)
```

**EXERCISE 2:** What is the general pattern in the h-clustering data?  
Using what you learned from the city example, what is the subcluster that looks very different than the rest of the samples?  
*Hint: It is a group of 3 libraries. You will have to plot this yourself and stretch it out. The rendering on the website compresses the output.*

Mostly the graph has libraries that intercorrelate very well, so they are spread under the same branch and spread evenly, but the left most three libraries seem to be a very different subcluster. If forms a different branch at first.

**SDR** -1 Grouping by genoytpe, tissue, replicates, etc...

```{r}
plot(gene_hclust_col) #redraw the tree everytime before adding the rectangles
rect.hclust(gene_hclust_col, k = 4, border = "red")
```

**Exercise 3:**
First, read the help file for `rect.hclust()`, then:

__a__ With k = 4 as one of the arguments to the rect.hclust() function, what is the largest and smallest group contained within the rectangles? 

From left to right, the first one is the smallest group, and the second is the largest group.

__b__ What does the k parameter specify?

The parameter represents the distances among these libraries, or in other word the level of correlation.

**SDR** -0.5 The number of clusters (boxes)

__c__ Play with the k-values between 3 and 7. Describe how the size of the clusters change when changing between k-values.
```{r}
plot(gene_hclust_col) #redraw the tree everytime before adding the rectangles
rect.hclust(gene_hclust_col, k = 3, border = "red")
```
```{r}
plot(gene_hclust_col) #redraw the tree everytime before adding the rectangles
rect.hclust(gene_hclust_col, k = 5, border = "red")
```
```{r}
plot(gene_hclust_col) #redraw the tree everytime before adding the rectangles
rect.hclust(gene_hclust_col, k = 6, border = "red")
```

```{r}
plot(gene_hclust_col) #redraw the tree everytime before adding the rectangles
rect.hclust(gene_hclust_col, k = 7, border = "red")
```
I found that the furthest and smallest outgroup is very stable because it is away from others, and the libraries in the largest group has strong correlation, so even k goes up due to their short distance between each other they are usually considered together, the libraries in the right has not very close correlation so more groups can be devided from the right half libraries.
```{r}
library(pvclust)
?pvclust #check out the documentation

set.seed(12456) #This ensure that we will have consistent results with one another

fit <- pvclust(GxE_counts, method.hclust = "ward.D", method.dist = "euclidean", nboot = 50)
```
```{r}
plot(fit)
```



**EXERCISE 4:** After running the 50 bootstrap samples, make a new plot but change nboot up to 1000. In general what happens to BP and AU?

```{r}
fit2 <- pvclust(GxE_counts, method.hclust = "ward.D", method.dist = "euclidean", nboot = 1000)
plot(fit2)
```
Slightly, BP increases and AU decreases.

**SDR** -1 Reversed

**Exercise 5:** 
We used the scale rows option. This is necessary so that every *row* in the data set will be on the same scale when visualized in the heatmap. This is to prevent really large values somewhere in the data set dominating the heatmap signal. Remember if you still have this data set in memory you can take a look at a printed version to the terminal. Compare the distance matrix that you printed with the colors of the heat map. See the advantage of working with small test sets? Take a look at your plot of the cities heatmap and interpret what a dark red value and a light yellow value in the heatmap would mean in geographic distance. Provide an example of of each in your explanation.
```{r}
library(gplots) #not to be confused with ggplot2!
head(cities)
```
```{r}
heatmap.2(as.matrix(cities), Rowv=as.dendrogram(cities_hclust), scale="row", density.info="none", trace="none")
```
Red means short geographic distance (such as distance between same cities, DEN and DEN, supposed to be 0 and the block is very red), and yellow means long geographic distance(such as SF and MIA, 3053, very far away).


**Exercise 6:** 
The genes are overplotted so we cannot distinguish one from another. However, what is the most obvious pattern that you can pick out from this data? Describe what you see. Make sure you plot this in your own session so you can stretch it out.
*Hint It will be a similar pattern as you noticed in the h-clustering example.*
```{r}
plot(gene_hclust_row)
heatmap.2(GxE_counts, Rowv = as.dendrogram(gene_hclust_row), scale = "row", density.info="none", trace="none")
```

It is obvious that the left most three libraries are yellower than the rest part. The right big branch seems to have subgroups, but it is hard to distinguish with this plot.

**Exercise 7:** In the similar way that you interpreted the color values of the heatmap for the city example, come up with a biological interpretation of the yellow vs. red color values in the heatmap. What would this mean for the pattern that you described in exercise 6? Discuss.  What if the heat map data (brass_voom_E) had not been adjusted/normalized for library size?  Could that lead to a technical explanation for the pattern?

It means that the left most three libraries have very weak correlation with the genes in the y scale compared to the rest of the libraries. If the heat map data had not been adjusted for library size, the result graph will not represent truly the correlation but would be biased by size, since the plotting usually consider the input data to be normally distributted.

**SDR** -1 Yellow = higher expression, red = lower expression

**Exercise 8:** Pretty Colors! Describe what you see visually with 2, 5, 9, and 15 clusters using either method. Why would it be a bad idea to have to few or to many clusters? Discuss with a specific example comparing few vs. many k-means. Justify your choice of too many and too few clusters by describing what you see in each case.
```{r}
library(ggplot2)
```
```{r}
prcomp_counts <- prcomp(t(GxE_counts)) #gene wise
scores <- as.data.frame(prcomp_counts$rotation)[,c(1,2)]

set.seed(25) #make this repeatable as kmeans has random starting positions
fit <- kmeans(GxE_counts, 9)
clus <- as.data.frame(fit$cluster)
names(clus) <- paste("cluster")

plotting <- merge(clus, scores, by = "row.names")
plotting$cluster <- as.factor(plotting$cluster)

# plot of observations
ggplot(data = plotting, aes(x = PC1, y = PC2, label = Row.names, color = cluster)) +
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  geom_point(alpha = 0.8, size = 4, stat = "identity") 
```
With the number of k, the dots are differently splitted into k colors. With two little k, such as 2, the plot shows too little details and give too little information, only splitting the samples in two clusters. With too large k, such as 15, the plot is very messy and one can no longer observe a valuable pattern from the graph.

```{r}
library(cluster)
set.seed(125)
gap <- clusGap(GxE_counts, FUN = kmeans, iter.max = 30, K.max = 20, B = 500, verbose=interactive())
plot(gap, main = "Gap Statistic")
```

**Exercise 9:** Based on the above Gap statistic plot, at what number of k clusters (x-axis) do you start to see diminishing returns? To put this another way, at what value of k does k-1 and k+1 start to look the same for the first time? Or yet another way, when are you getting diminishing returns for adding more k-means? See if you can make the trade off of trying to capture a lot of variation in the data as the Gap statistic increases, but you do not want to add too many k-means because your returns diminish as you add more. Explain your answer using the plot as a guide to help you interpret the data.

When k reaches 8 or 9, the k-1 and k+1 start to look the same. With higher k, the graph neither increases or decreases in a way, but swing slightly.

**Exercise 10:** What did clusGap() calculate? How does this compare to your answer from Exercise 9? Make a plot using the kmeans functions as you did before, but choose the number of k-means you chose and the number of k-means that are calculated from the Gap Statistic. Describe the differences in the plots.
```{r}
with(gap, maxSE(Tab[,"gap"], Tab[,"SE.sim"], method="firstSEmax"))
```
The number calculated here is where the plot starts to have diminishing returns. It is a little bit smaller than my direct observation.

```{r}
#From clusGap()

prcomp_counts <- prcomp(t(GxE_counts)) #gene wise
scores <- as.data.frame(prcomp_counts$rotation)[,c(1,2)]

set.seed(25) #make this repeatable as kmeans has random starting positions
fit <- kmeans(GxE_counts, 7)
clus <- as.data.frame(fit$cluster)
names(clus) <- paste("cluster")

plotting <- merge(clus, scores, by = "row.names")
plotting$cluster <- as.factor(plotting$cluster)

# plot of observations
ggplot(data = plotting, aes(x = PC1, y = PC2, label = Row.names, color = cluster)) +
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  geom_point(alpha = 0.8, size = 4, stat = "identity") 
```
```{r}
#my observation
prcomp_counts <- prcomp(t(GxE_counts)) #gene wise
scores <- as.data.frame(prcomp_counts$rotation)[,c(1,2)]

set.seed(25) #make this repeatable as kmeans has random starting positions
fit <- kmeans(GxE_counts, 8)
clus <- as.data.frame(fit$cluster)
names(clus) <- paste("cluster")

plotting <- merge(clus, scores, by = "row.names")
plotting$cluster <- as.factor(plotting$cluster)

# plot of observations
ggplot(data = plotting, aes(x = PC1, y = PC2, label = Row.names, color = cluster)) +
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") +
  geom_point(alpha = 0.8, size = 4, stat = "identity") 
```

The only difference is when k=8, the pink group is splitted out from the green group. The two groups seem to overlap so there seems little geographic difference by observation, so k=7 should be a better graph.
